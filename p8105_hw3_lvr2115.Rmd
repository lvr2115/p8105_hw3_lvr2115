---
title: "p8105_hw3_lvr2115"
author: "Laura Robles-Torres"
date: "2023-10-10"
output: github_document
---
```{r message=FALSE}
library(p8105.datasets)
data("instacart")
library(tidyverse)
library(dplyr)
```

```{r }
instacart = 
  instacart |> 
  as_tibble()
```

# Problem 1

The dataset is `r nrow(instacart)` rows and `r ncol(instacart)` columns. The 15 variables are `r ls(instacart)`. Each row in this dataset represents an object that was ordered from Instacart. There are variables to identify the order itself, including user ID ('user_id'), the order in which items were added to the cart ('add_to_cart_order'), and the order ID ('order_id'). There are variables to describe the items ordered per say, such as department ('department' and 'department_id'), the name of the product ('product_name'), and the aisle in which the product is found ('aisle' and 'aisle_id'), and whether or not the item has been ordered by this user previously ('reordered').  In total, there are `r instacart |> select(product_id) |> distinct() |> count()` products found in `r instacart |> select(user_id, order_id) |> distinct() |> count()` orders from `r instacart |> select(user_id) |> distinct() |> count()` distinct users.

How many aisles are there, and which aisles are the most items ordered from?

```{r}
instacart |> 
  group_by (aisle) |>
  summarize(n_obs=n()) |>
    arrange(desc(n_obs))
```

There are 134 aisles and the aisles from which the most items are ordered from are fresh vegetables and fresh fruits.  

This plot shows the number of items ordered in each aisle, only including aisles with more than 10000 items ordered, shown in ascending order. 

```{r message=FALSE}
instacart |>
  group_by(aisle) |>
  summarize(n_obs = n()) |>
  filter(n_obs > 10000) |> 
      mutate(aisle = fct_reorder(aisle, n_obs)) |> 
  ggplot(aes(x = aisle, y = n_obs)) + 
    geom_point() + geom_line() + 
    labs(title = "Number of items ordered in each aisle") +
    theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

This table shows the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”, including the number of times each item is ordered.

```{r message=FALSE}
instacart |>
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle) |>
  count(product_name) |>
  mutate(rank = min_rank(desc(n))) |> 
  filter(rank <=3) |> 
  arrange(desc(n)) |>
  knitr::kable()
```


This table shows the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week (0-6). 

```{r message=FALSE}
instacart |>
filter(product_name%in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
group_by(product_name, order_dow) |>
summarize (
  mean_hod=mean(order_hour_of_day, na.rm=TRUE)
) |>
pivot_wider(
    names_from = order_dow, 
    values_from = mean_hod) |>
  knitr::kable(digits = 1)
```

# Problem 2
```{r loading dataset}
library(p8105.datasets)
data("brfss_smart2010")
```

## Data cleaning 
```{r data cleaning}
brfss_smart2010_clean = 
  janitor::clean_names(brfss_smart2010) |>
  rename(state = locationabbr)

brfss_smart2010_overallhealth = filter(brfss_smart2010_clean, topic=="Overall Health" | response=="Excellent:Poor") |>
  mutate(recode_factor(response, "Poor" = "1", "Fair" = "2", "Good" = "3", "Very Good" = "4", "Very good" = "4", "Excellent" = "5"))
```

In 2002, CT, FL, MA, NC, NJ, PA were observed at 7 or more locations. 
In 2010, CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, WA were observed at 7 or more locations. 

```{r}
brfss_smart2010_clean |> 
  filter(year %in% c(2002)) |> 
  distinct(state,locationdesc) |>
  count(state) |>
  filter(n>=7) |>
  arrange(n) |>
  knitr::kable()

brfss_smart2010_clean |>
  filter(year %in% 2010) |>
  distinct(state, locationdesc) |>
  count(state) |> 
  filter(n >= 7) |>
  arrange(n) |>
  knitr::kable()
```

This dataset is limited to 'Excellent' responses, and contains: year, state, and a variable that averages the data_value across locations within a state named "avg_data_value". This plot shows the average value over time within a state. 
####HELP

```{r}
brfss_excellent = filter(brfss_smart2010_overallhealth, response == "Excellent") 

brfss_excellent |>
  group_by(state, year) |>
  summarize(
    avg_data_value = mean(data_value)
  ) |>
ggplot(aes(x = year, y = avg_data_value, color = state)) + 
    geom_point() + geom_line() +
    theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

```{r uploading patchwork package for panel plots}
library(patchwork)
```

Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State. 
####HELP 

```{r}
ny_response = 
  brfss_smart2010_overallhealth |> 
  filter(state == "NY", year %in% c(2006, 2010)) |>
  select(state, year, data_value, locationdesc)

ggplot(ny_response, aes(x = locationdesc, y = data_value) + geom_boxplot()
```

# Problem 3 

## Uploading and cleaning datasets
```{r cleaning accelerometer df, message=FALSE, warning=FALSE}
accelerometer = 
  read_csv("./nhanes_accel.csv") |>
  janitor::clean_names(case="snake") |>
  drop_na() |>
  mutate(
    seqn = as.factor(seqn)
  ) |>
  pivot_longer(
    min1:min1440,
    names_prefix = "min",
    names_to = "min",
    values_to= "physical_act"
  )
```

```{r cleaning demographic df, message=FALSE, warning=FALSE}
demographic = 
  read_csv("./nhanes_covar.csv",  skip = 4) |> 
  janitor::clean_names(case="snake") |>
  drop_na() |>
  filter(age>20) |>
  mutate(
    sex = 
      case_match(
        sex, 
        1 ~ "male", 
        2 ~ "female"), 
    education = 
      case_match(
        education, 
        1 ~ "less than HS", 
        2 ~ "HS",
        3 ~ "more than HS"), 
    sex = as.factor(sex),
    education = as.factor(education),
    seqn = as.factor(seqn)
  )
```

## Merging datasets
```{r merged df}
merged_nhanes = 
  left_join(demographic, accelerometer, by = c("seqn")) |>
  drop_na()
```

## Table and visualization for the number of men and women in each education category
```{r age distributions for women and men in each education category}
merged_nhanes |>
  group_by(sex,education) |>
  janitor::tabyl(sex, education) |>
  knitr::kable(digits=1)

merged_nhanes |>
ggplot(aes(x = sex, y=age)) +
  geom_boxplot()+
  facet_grid(. ~ education)+
  labs(
      x= "sex",
      y="age",
      title= "age distribution of women and men in each education category"
  )
```

Aggregate across minutes to create a total activity variable for each participant.  Plot these total activities (y-axis) against age (x-axis); your plot should compare men to women and have separate panels for each education level. Include a trend line or a smooth to illustrate differences. 

```{r}
activities_df = merged_nhanes |>
  group_by(seqn) |>
  mutate(
    total_activity=sum(physical_act))

activities_df |>
  ggplot(aes(x=age, y = total_activity, color=sex)) +
  geom_point()+
  geom_smooth()+
  facet_grid(.~education) +
  labs(
      x= "age",
      y="total activity",
      title= "total activity & age by education level")
```

Accelerometer data allows the inspection activity over the course of the day. Make a three-panel plot that shows the 24-hour activity time courses for each education level and use color to indicate sex. Describe in words any patterns or conclusions you can make based on this graph; including smooth trends may help identify differences.

```{r inspection data pivoting}
inspect_act=merged_nhanes |>
  pivot_longer(
    cols = starts_with ("min"),
    names_to = "minute",
    names_prefix="min",
    values_to="activity") |>
  mutate(minute=as.numeric(minute))
```

###HELP 
```{r inspection data visualization}
inspect_act |>
  ggplot(aes(x=minute, y=activity, color=sex))+
    geom_line(aes(group=seqn), alpha=0.3) + 
    geom_smooth() +
    facet_grid(.~education)+
    labs(
      x = "time",
      y = "activity",
      title = "24-hour activity time courses by education level and sex",
      color="sex"
    )
```

